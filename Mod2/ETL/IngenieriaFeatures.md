# Ingenier칤a de Features en Machine Learning

La **ingenier칤a de features** (o *feature engineering*) en Machine Learning es el proceso de **transformar los datos brutos en variables** que un modelo pueda entender y aprovechar para hacer **mejores predicciones**.

Es uno de los pasos m치s importantes del flujo de trabajo en ML, y puede marcar la diferencia entre un modelo **mediocre** y uno de **alto rendimiento**.

Nelson Zepeda, Julio 2025

---

## 쯈u칠 es exactamente una "feature"?

Una **feature** (o caracter칤stica) es una **columna o variable** que representa una propiedad de tus datos.

### Ejemplos:

- En un modelo de predicci칩n de precios de casas:
  - `tama침o_m2`, `nro_habitaciones`, `ubicaci칩n`, `a침o_construcci칩n`

- En un modelo de clasificaci칩n de texto:
  - `longitud_del_texto`, `frecuencia_de_palabras`, `presencia_de_palabra_clave`

---

## 쯈u칠 incluye la ingenier칤a de features?

Aqu칤 algunas tareas t칤picas:

| T칠cnica                      | Descripci칩n                                      | Ejemplo                                      |
|-----------------------------|--------------------------------------------------|----------------------------------------------|
| Selecci칩n de features       | Elegir solo las variables m치s 칰tiles             | Eliminar columnas redundantes o irrelevantes |
| Transformaci칩n de variables | Cambiar la forma de una variable                 | Aplicar logaritmo a una variable sesgada     |
| Codificaci칩n categ칩rica     | Convertir texto en n칰meros                       | One-hot encoding para columna `color`        |
| Escalado/Normalizaci칩n      | Poner todas las variables en la misma escala     | `StandardScaler`, `MinMaxScaler`             |
| Generaci칩n de nuevas features | Crear variables derivadas                    | `edad = 2025 - a침o_nacimiento`               |
| Tratamiento de fechas       | Extraer informaci칩n 칰til de fechas              | D칤a de la semana, mes, feriado, etc.         |
| Manejo de valores faltantes | Imputar o eliminar `NaN`                         | Reemplazar con media o modelo predictivo     |
| Interacciones               | Combinar variables entre s칤                      | `precio_unitario = total / cantidad`         |

---

## 쯇or qu칠 es importante?

- Un modelo **simple con buenas features** puede superar a un modelo **complejo con malas features**.
- Mejora la **interpretabilidad**, **precisi칩n** y **robustez** del modelo.
- Permite **incorporar conocimiento del dominio** en el proceso de aprendizaje.

---

## Ejemplo pr치ctico

Sup칩n que est치s trabajando con **datos de transacciones de tarjetas de cr칠dito**. En lugar de usar solo el monto (`amount`), podr칤as crear:

- `is_weekend`: si la transacci칩n fue en fin de semana  
- `hour_of_day`: hora de la transacci칩n  
- `log_amount`: logaritmo del monto (para reducir sesgo)  
- `avg_amount_user_30d`: gasto promedio del usuario en 30 d칤as  

Estas nuevas features pueden capturar **patrones m치s complejos** y mejorar el rendimiento del modelo.

---

##  Ejemplo de Codificaci칩n Categ칩rica

###  Objetivo
Convertir una columna categ칩rica (`color`) en variables num칠ricas que un modelo de Machine Learning pueda procesar.


### 游 Datos Originales

| id | color   |
|----|---------|
| 1  | rojo    |
| 2  | azul    |
| 3  | verde   |
| 4  | rojo    |



### Aplicando One-Hot Encoding

One-hot encoding crea **una nueva columna por cada categor칤a** posible y marca con `1` si esa fila pertenece a esa categor칤a, y `0` en caso contrario.

| id | color_rojo | color_azul | color_verde |
|----|------------|------------|-------------|
| 1  | 1          | 0          | 0           |
| 2  | 0          | 1          | 0           |
| 3  | 0          | 0          | 1           |
| 4  | 1          | 0          | 0           |



### 쯇or qu칠 se hace esto?

- Los modelos como regresi칩n log칤stica, redes neuronales y 치rboles **no pueden procesar texto directamente**.
- One-hot encoding evita que el modelo **asuma un orden inexistente** (como lo har칤a el Label Encoding).



### En Python con pandas

```python
import pandas as pd

df = pd.DataFrame({ 'color': ['rojo', 'azul', 'verde', 'rojo'] })
encoded = pd.get_dummies(df, columns=['color'])
print(encoded)
```
---

##  Ejemplo de Generaci칩n de Nuevas Features

###  Objetivo
Crear variables nuevas que **no existen directamente en los datos**, pero que pueden capturar relaciones importantes y mejorar el rendimiento del modelo.



###  Datos Originales

| id | fecha_nacimiento | fecha_transaccion | total | cantidad |
|----|------------------|-------------------|-------|----------|
| 1  | 1990-06-15       | 2025-07-09        | 100   | 4        |
| 2  | 1985-02-01       | 2025-07-09        | 60    | 2        |
| 3  | 2000-10-23       | 2025-07-09        | 150   | 3        |



###  Nuevas Features Generadas

| id | edad_usuario | precio_unitario | dia_semana_transaccion |
|----|--------------|-----------------|-------------------------|
| 1  | 35           | 25.0            | martes                  |
| 2  | 40           | 30.0            | martes                  |
| 3  | 24           | 50.0            | martes                  |

- `edad_usuario`: calculada como diferencia entre a침o de transacci칩n y a침o de nacimiento
- `precio_unitario`: total / cantidad
- `dia_semana_transaccion`: d칤a de la semana extra칤do de la fecha



###  En Python con pandas

```python
import pandas as pd

df = pd.DataFrame({
    'fecha_nacimiento': ['1990-06-15', '1985-02-01', '2000-10-23'],
    'fecha_transaccion': ['2025-07-09'] * 3,
    'total': [100, 60, 150],
    'cantidad': [4, 2, 3]
})

df['fecha_nacimiento'] = pd.to_datetime(df['fecha_nacimiento'])
df['fecha_transaccion'] = pd.to_datetime(df['fecha_transaccion'])

# Nueva feature: edad del usuario
df['edad_usuario'] = df['fecha_transaccion'].dt.year - df['fecha_nacimiento'].dt.year

# Nueva feature: precio por unidad
df['precio_unitario'] = df['total'] / df['cantidad']

# Nueva feature: d칤a de la semana
df['dia_semana_transaccion'] = df['fecha_transaccion'].dt.day_name()

print(df)
```
---

## Ejemplo de Tratamiento de Fechas

### Objetivo
Extraer **informaci칩n 칰til y estructurada** a partir de variables de tipo fecha para enriquecer el dataset y mejorar las predicciones del modelo.


### Datos Originales

| id | fecha_transaccion     |
|----|------------------------|
| 1  | 2025-07-09             |
| 2  | 2025-12-24             |
| 3  | 2025-01-01             |



### Features Derivadas

| id | a침o | mes | dia | dia_semana | es_fin_de_semana |
|----|-----|-----|-----|------------|------------------|
| 1  | 2025|  7  |  9  | mi칠rcoles  | False            |
| 2  | 2025| 12  | 24  | mi칠rcoles  | False            |
| 3  | 2025|  1  |  1  | mi칠rcoles  | False            |



### En Python con pandas

```python
import pandas as pd

df = pd.DataFrame({
    'fecha_transaccion': ['2025-07-09', '2025-12-24', '2025-01-01']
})

df['fecha_transaccion'] = pd.to_datetime(df['fecha_transaccion'])

# Extraer componentes de fecha
df['a침o'] = df['fecha_transaccion'].dt.year
df['mes'] = df['fecha_transaccion'].dt.month
df['dia'] = df['fecha_transaccion'].dt.day
df['dia_semana'] = df['fecha_transaccion'].dt.day_name()
df['es_fin_de_semana'] = df['fecha_transaccion'].dt.dayofweek >= 5  # s치bado=5, domingo=6

print(df)
```
---
## Bonus: 쮻칩nde ocurre la ingenier칤a de features?

La ingenier칤a de features suele hacerse **antes del entrenamiento del modelo**, como parte del **pipeline de preprocesamiento**. En proyectos m치s avanzados, se incluyen pasos autom치ticos con herramientas como:

- `scikit-learn` Pipelines
- `FeatureUnion`
- `Featuretools`
- `dbt` o herramientas de orquestaci칩n de datos

