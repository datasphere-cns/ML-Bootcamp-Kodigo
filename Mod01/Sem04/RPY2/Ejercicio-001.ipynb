{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejemplo Práctico: Análisis de Transacciones con Tarjeta de Crédito usando RPy2\n",
    "----\n",
    "Este ejemplo demuestra cómo usar **RPy2** para combinar:\n",
    "- Manipulación de datos en Python (pandas)\n",
    "- Análisis estadístico avanzado en R\n",
    "- Visualización especializada con ggplot2\n",
    "\n",
    "**Caso de uso:** Detección de patrones fraudulentos y análisis de comportamiento de compras.\n",
    "\n",
    "¿Qué hace este análisis de transacciones?\n",
    "Este Jupyter Notebook es una herramienta que simula y analiza el comportamiento de transacciones con tarjeta de crédito. Su objetivo principal es entender patrones de compra y detectar posibles fraudes, combinando las fortalezas de dos lenguajes de programación: Python y R.\n",
    "\n",
    "Piensa en él como un análista de fraude que examina miles de compras para encontrar lo que es normal y lo que podría ser sospechoso.\n",
    "\n",
    "¿Cómo funciona el \"análista\" de transacciones?\n",
    "El proceso se divide en cinco pasos principales, cada uno construido sobre el anterior:\n",
    "\n",
    "Generación de Datos de Prueba (Simulación de Compras)\n",
    "¿Qué hace? Crea un conjunto grande y falso de transacciones de tarjeta de crédito, como si miles de personas estuvieran comprando en diferentes lugares y momentos.\n",
    "\n",
    "¿Por qué es útil? Nos permite practicar el análisis sin usar datos reales y sensibles. Incluye algunos \"fraudes\" simulados para que el detective tenga algo que buscar.\n",
    "\n",
    "¿Cómo lo hace? Utiliza la librería Python (Pandas) para construir estas transacciones con detalles como el monto, la fecha, la categoría de la tienda, la ciudad, e incluso si es un fraude (conocido solo por el script en este punto).\n",
    "Análisis Básico con Python\n",
    "\n",
    "¿Qué hace? Realiza un primer vistazo rápido a los datos de las transacciones.\n",
    "\n",
    "¿Por qué es útil? Nos da una idea general de cómo se distribuyen los montos, cuáles son las categorías de gasto más comunes y cuánto dinero se mueve en cada una. También identifica transacciones inusualmente grandes.\n",
    "\n",
    "¿Cómo lo hace? Emplea las capacidades de Python (Pandas) para calcular estadísticas como promedios, sumas y el número de transacciones por tipo de tienda.\n",
    "\n",
    "Análisis Estadístico Avanzado con R\n",
    "\n",
    "¿Qué hace? Suma las capacidades de un experto en estadísticas (R) para profundizar en los patrones de los datos.\n",
    "\n",
    "¿Por qué es útil?\n",
    "Entiende las distribuciones: Nos dice si los montos de compra siguen un patrón predecible o si son muy variados.\n",
    "Compara categorías: Determina si el gasto promedio es significativamente diferente entre categorías (ej., ¿se gasta mucho más en electrónicos que en farmacia?).\n",
    "\n",
    "Predice Fraudes: Intenta construir un \"modelo\" que aprenda qué características (como el monto o la hora) hacen que una transacción sea más propensa a ser fraudulenta.\n",
    "\n",
    "Analiza el tiempo: Busca tendencias y ciclos en el total de transacciones a lo largo del tiempo (ej., ¿más compras los fines de semana o a fin de mes?).\n",
    "\n",
    "¿Cómo lo hace? Usa RPy2 para enviar los datos de Python a R, donde se aplican métodos estadísticos avanzados.\n",
    "Visualización Profesional con R (ggplot2)\n",
    "\n",
    "¿Qué hace? Crea gráficos claros y atractivos que nos ayudan a \"ver\" los patrones y resultados del análisis.\n",
    "\n",
    "¿Por qué es útil? Es mucho más fácil entender las relaciones en los datos con un buen gráfico que leyendo números.\n",
    "\n",
    "¿Cómo lo hace? Utiliza RPy2 para enviar los datos a R y luego aprovecha ggplot2, una de las librerías de gráficos más potentes de R, para dibujar:\n",
    "Gráficos que muestran cómo varían los montos en cada categoría de compra.\n",
    "Gráficos que siguen la cantidad de transacciones (normales y fraudulentas) a lo largo de las semanas.\n",
    "\"Mapas de calor\" que muestran cuándo (qué día y hora) hay más actividad de transacciones.\n",
    "Comparación de Rendimiento\n",
    "\n",
    "¿Qué hace? Mide qué tan rápido realizan algunas operaciones estadísticas Python y R.\n",
    "\n",
    "¿Por qué es útil? Aunque ambos son muy eficientes, esta comparación nos da una idea de cuándo uno podría ser ligeramente mejor que el otro para ciertas tareas, incluso considerando la comunicación entre ellos.\n",
    "\n",
    "¿Cómo lo hace? Ejecuta cálculos básicos (como la media y la desviación estándar) en Python (NumPy) y luego los repite en R para comparar los tiempos.\n",
    "En resumen, este script actúa como un centro de comando donde Python organiza los datos y las instrucciones, y R entra en acción cuando se necesita un análisis estadístico profundo o gráficos especializados, todo para ayudarnos a descubrir secretos ocultos en el comportamiento de las transacciones.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importar librerías de Python\n",
    "Importamos las librerías de Python necesarias para la manipulación de datos y la generación de datos ficticios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Configuración de RPy2\n",
    "----\n",
    "Configuramos RPy2 para permitir la interacción entre Python y R. Esto incluye la activación de conversiones automáticas de tipos de datos y la importación de paquetes R."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importar módulos de RPy2\n",
    "Estos módulos son esenciales para la comunicación entre Python y R."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pip install rpy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verificando PATH después de añadir R y RTools:\n",
      "C:\\rtools42\\usr\\bin;C:\\PROGRA~1\\R\\R-42~1.2\\bin\\x64;C:\\virtual_environment\\bootcamp03\\Scripts;C:\\Program Files (x86)\\Common Files\\Oracle\\Java\\java8path;C:\\Program Files (x86)\\Common Files\\Oracle\\Java\\javapath;C:\\Program Files\\Microsoft\\jdk-11.0.27.6-hotspot\\bin;C:\\Program Files (x86)\\VMware\\VMware Player\\bin\\;C:\\WINDOWS\\system32;C:\\WINDOWS;C:\\WINDOWS\\System32\\Wbem;C:\\WINDOWS\\System32\\WindowsPowerShell\\v1.0\\;C:\\WINDOWS\\System32\\OpenSSH\\;C:\\Program Files\\Microsoft SQL Server\\Client SDK\\ODBC\\170\\Tools\\Binn\\;C:\\Program Files (x86)\\Microsoft SQL Server\\150\\Tools\\Binn\\;C:\\Program Files\\Microsoft SQL Server\\150\\Tools\\Binn\\;C:\\Program Files\\Microsoft SQL Server\\150\\DTS\\Binn\\;C:\\Program Files (x86)\\Microsoft SQL Server\\150\\DTS\\Binn\\;C:\\Program Files\\Azure Data Studio\\bin;C:\\Program Files\\PuTTY\\;C:\\Program Files\\dotnet\\;C:\\Program Files\\Git\\cmd;C:\\Program Files (x86)\\Google\\Cloud SDK\\google-cloud-sdk\\bin;C:\\Program Files\\Snowflake SnowSQL\\;C:\\Program Files\\Docker\\Docker\\resources\\bin;C:\\Program Files\\MySQL\\MySQL Shell 8.0\\bin\\;C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\\;C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\;C:\\Users\\Admin\\AppData\\Local\\Microsoft\\WindowsApps;C:\\Program Files\\Azure Data Studio\\bin;C:\\Users\\Admin\\AppData\\Local\\Programs\\Microsoft VS Code\\bin;C:\\Users\\Admin\\AppData\\Local\\GitHubDesktop\\bin;C:\\Users\\Admin\\.dotnet\\tools\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error importing in API mode: ImportError('On Windows, cffi mode \"ANY\" is only \"ABI\".')\n",
      "Trying to import in ABI mode.\n",
      "C:\\virtual_environment\\bootcamp03\\lib\\site-packages\\rpy2\\rinterface\\__init__.py:1211: UserWarning: Environment variable \"PATH\" redefined by R and overriding existing variable. Current: \"C:\\rtools42\\usr\\bin;C:\\PROGRA~1\\R\\R-42~1.2\\bin\\x64;C:\\virtual_environment\\bootcamp03\\Scripts;C:\\Program Files (x86)\\Common Files\\Oracle\\Java\\java8path;C:\\Program Files (x86)\\Common Files\\Oracle\\Java\\javapath;C:\\Program Files\\Microsoft\\jdk-11.0.27.6-hotspot\\bin;C:\\Program Files (x86)\\VMware\\VMware Player\\bin\\;C:\\WINDOWS\\system32;C:\\WINDOWS;C:\\WINDOWS\\System32\\Wbem;C:\\WINDOWS\\System32\\WindowsPowerShell\\v1.0\\;C:\\WINDOWS\\System32\\OpenSSH\\;C:\\Program Files\\Microsoft SQL Server\\Client SDK\\ODBC\\170\\Tools\\Binn\\;C:\\Program Files (x86)\\Microsoft SQL Server\\150\\Tools\\Binn\\;C:\\Program Files\\Microsoft SQL Server\\150\\Tools\\Binn\\;C:\\Program Files\\Microsoft SQL Server\\150\\DTS\\Binn\\;C:\\Program Files (x86)\\Microsoft SQL Server\\150\\DTS\\Binn\\;C:\\Program Files\\Azure Data Studio\\bin;C:\\Program Files\\PuTTY\\;C:\\Program Files\\dotnet\\;C:\\Program Files\\Git\\cmd;C:\\Program Files (x86)\\Google\\Cloud SDK\\google-cloud-sdk\\bin;C:\\Program Files\\Snowflake SnowSQL\\;C:\\Program Files\\Docker\\Docker\\resources\\bin;C:\\Program Files\\MySQL\\MySQL Shell 8.0\\bin\\;C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\\;C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\;C:\\Users\\Admin\\AppData\\Local\\Microsoft\\WindowsApps;C:\\Program Files\\Azure Data Studio\\bin;C:\\Users\\Admin\\AppData\\Local\\Programs\\Microsoft VS Code\\bin;C:\\Users\\Admin\\AppData\\Local\\GitHubDesktop\\bin;C:\\Users\\Admin\\.dotnet\\tools;C:\\PROGRA~1\\R\\R-42~1.2\\bin\\x64\", R: \"C:\\rtools42/x86_64-w64-mingw32.static.posix/bin;C:\\rtools42/usr/bin;C:\\rtools42\\usr\\bin;C:\\PROGRA~1\\R\\R-42~1.2\\bin\\x64;C:\\virtual_environment\\bootcamp03\\Scripts;C:\\Program Files (x86)\\Common Files\\Oracle\\Java\\java8path;C:\\Program Files (x86)\\Common Files\\Oracle\\Java\\javapath;C:\\Program Files\\Microsoft\\jdk-11.0.27.6-hotspot\\bin;C:\\Program Files (x86)\\VMware\\VMware Player\\bin\\;C:\\WINDOWS\\system32;C:\\WINDOWS;C:\\WINDOWS\\System32\\Wbem;C:\\WINDOWS\\System32\\WindowsPowerShell\\v1.0\\;C:\\WINDOWS\\System32\\OpenSSH\\;C:\\Program Files\\Microsoft SQL Server\\Client SDK\\ODBC\\170\\Tools\\Binn\\;C:\\Program Files (x86)\\Microsoft SQL Server\\150\\Tools\\Binn\\;C:\\Program Files\\Microsoft SQL Server\\150\\Tools\\Binn\\;C:\\Program Files\\Microsoft SQL Server\\150\\DTS\\Binn\\;C:\\Program Files (x86)\\Microsoft SQL Server\\150\\DTS\\Binn\\;C:\\Program Files\\Azure Data Studio\\bin;C:\\Program Files\\PuTTY\\;C:\\Program Files\\dotnet\\;C:\\Program Files\\Git\\cmd;C:\\Program Files (x86)\\Google\\Cloud SDK\\google-cloud-sdk\\bin;C:\\Program Files\\Snowflake SnowSQL\\;C:\\Program Files\\Docker\\Docker\\resources\\bin;C:\\Program Files\\MySQL\\MySQL Shell 8.0\\bin\\;C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\\;C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\;C:\\Users\\Admin\\AppData\\Local\\Microsoft\\WindowsApps;C:\\Program Files\\Azure Data Studio\\bin;C:\\Users\\Admin\\AppData\\Local\\Programs\\Microsoft VS Code\\bin;C:\\Users\\Admin\\AppData\\Local\\GitHubDesktop\\bin;C:\\Users\\Admin\\.dotnet\\tools;C:\\PROGRA~1\\R\\R-42~1.2\\bin\\x64\"\n",
      "  warnings.warn(\n",
      "C:\\virtual_environment\\bootcamp03\\lib\\site-packages\\rpy2\\rinterface\\__init__.py:1211: UserWarning: Environment variable \"R_HOME\" redefined by R and overriding existing variable. Current: \"C:\\PROGRA~1\\R\\R-42~1.2\", R: \"C:/PROGRA~1/R/R-42~1.2\"\n",
      "  warnings.warn(\n",
      "C:\\virtual_environment\\bootcamp03\\lib\\site-packages\\rpy2\\rinterface\\__init__.py:1211: UserWarning: Environment variable \"PATH\" redefined by R and overriding existing variable. Current: \"C:\\rtools42/x86_64-w64-mingw32.static.posix/bin;C:\\rtools42/usr/bin;C:\\rtools42\\usr\\bin;C:\\PROGRA~1\\R\\R-42~1.2\\bin\\x64;C:\\virtual_environment\\bootcamp03\\Scripts;C:\\Program Files (x86)\\Common Files\\Oracle\\Java\\java8path;C:\\Program Files (x86)\\Common Files\\Oracle\\Java\\javapath;C:\\Program Files\\Microsoft\\jdk-11.0.27.6-hotspot\\bin;C:\\Program Files (x86)\\VMware\\VMware Player\\bin\\;C:\\WINDOWS\\system32;C:\\WINDOWS;C:\\WINDOWS\\System32\\Wbem;C:\\WINDOWS\\System32\\WindowsPowerShell\\v1.0\\;C:\\WINDOWS\\System32\\OpenSSH\\;C:\\Program Files\\Microsoft SQL Server\\Client SDK\\ODBC\\170\\Tools\\Binn\\;C:\\Program Files (x86)\\Microsoft SQL Server\\150\\Tools\\Binn\\;C:\\Program Files\\Microsoft SQL Server\\150\\Tools\\Binn\\;C:\\Program Files\\Microsoft SQL Server\\150\\DTS\\Binn\\;C:\\Program Files (x86)\\Microsoft SQL Server\\150\\DTS\\Binn\\;C:\\Program Files\\Azure Data Studio\\bin;C:\\Program Files\\PuTTY\\;C:\\Program Files\\dotnet\\;C:\\Program Files\\Git\\cmd;C:\\Program Files (x86)\\Google\\Cloud SDK\\google-cloud-sdk\\bin;C:\\Program Files\\Snowflake SnowSQL\\;C:\\Program Files\\Docker\\Docker\\resources\\bin;C:\\Program Files\\MySQL\\MySQL Shell 8.0\\bin\\;C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\\;C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\;C:\\Users\\Admin\\AppData\\Local\\Microsoft\\WindowsApps;C:\\Program Files\\Azure Data Studio\\bin;C:\\Users\\Admin\\AppData\\Local\\Programs\\Microsoft VS Code\\bin;C:\\Users\\Admin\\AppData\\Local\\GitHubDesktop\\bin;C:\\Users\\Admin\\.dotnet\\tools;C:\\PROGRA~1\\R\\R-42~1.2\\bin\\x64\", R: \"C:\\rtools42/x86_64-w64-mingw32.static.posix/bin;C:\\rtools42/usr/bin;C:\\rtools42/x86_64-w64-mingw32.static.posix/bin;C:\\rtools42/usr/bin;C:\\rtools42/x86_64-w64-mingw32.static.posix/bin;C:\\rtools42/usr/bin;C:\\rtools42\\usr\\bin;C:\\PROGRA~1\\R\\R-42~1.2\\bin\\x64;C:\\virtual_environment\\bootcamp03\\Scripts;C:\\Program Files (x86)\\Common Files\\Oracle\\Java\\java8path;C:\\Program Files (x86)\\Common Files\\Oracle\\Java\\javapath;C:\\Program Files\\Microsoft\\jdk-11.0.27.6-hotspot\\bin;C:\\Program Files (x86)\\VMware\\VMware Player\\bin\\;C:\\WINDOWS\\system32;C:\\WINDOWS;C:\\WINDOWS\\System32\\Wbem;C:\\WINDOWS\\System32\\WindowsPowerShell\\v1.0\\;C:\\WINDOWS\\System32\\OpenSSH\\;C:\\Program Files\\Microsoft SQL Server\\Client SDK\\ODBC\\170\\Tools\\Binn\\;C:\\Program Files (x86)\\Microsoft SQL Server\\150\\Tools\\Binn\\;C:\\Program Files\\Microsoft SQL Server\\150\\Tools\\Binn\\;C:\\Program Files\\Microsoft SQL Server\\150\\DTS\\Binn\\;C:\\Program Files (x86)\\Microsoft SQL Server\\150\\DTS\\Binn\\;C:\\Program Files\\Azure Data Studio\\bin;C:\\Program Files\\PuTTY\\;C:\\Program Files\\dotnet\\;C:\\Program Files\\Git\\cmd;C:\\Program Files (x86)\\Google\\Cloud SDK\\google-cloud-sdk\\bin;C:\\Program Files\\Snowflake SnowSQL\\;C:\\Program Files\\Docker\\Docker\\resources\\bin;C:\\Program Files\\MySQL\\MySQL Shell 8.0\\bin\\;C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\\;C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\;C:\\Users\\Admin\\AppData\\Local\\Microsoft\\WindowsApps;C:\\Program Files\\Azure Data Studio\\bin;C:\\Users\\Admin\\AppData\\Local\\Programs\\Microsoft VS Code\\bin;C:\\Users\\Admin\\AppData\\Local\\GitHubDesktop\\bin;C:\\Users\\Admin\\.dotnet\\tools;C:\\PROGRA~1\\R\\R-42~1.2\\bin\\x64\"\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Importando paquetes R...\n",
      "  ggplot2 cargado correctamente\n",
      "  dplyr cargado correctamente\n",
      "  lubridate cargado correctamente\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R callback write-console: Warning:  \n",
      "R callback write-console:  package 'plotly' is in use and will not be installed\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Error al cargar plotly: list index out of range\n",
      "  Intentando instalar plotly...\n",
      "  plotly instalado y cargado\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys # Importar sys para salir si hay problemas con R_HOME\n",
    "\n",
    "# --- INICIA EL TROUBLESHOOTING / CONFIGURACIÓN ---\n",
    "# 1. Define la ruta RAÍZ de tu instalación de R.\n",
    "#    ¡Usamos la ruta corta que R.home() te devolvió, que es más segura!\n",
    "#    'C:/PROGRA~1/R/R-42~1.2' es equivalente a 'C:\\\\Program Files\\\\R\\\\R-4.2.2'\n",
    "r_home_path = 'C:\\\\PROGRA~1\\\\R\\\\R-42~1.2' \n",
    "\n",
    "# 2. Establece la variable de entorno R_HOME.\n",
    "#    RPy2 usa R_HOME para encontrar la instalación base de R.\n",
    "os.environ['R_HOME'] = r_home_path\n",
    "os.environ['LANG'] = 'en_US.UTF-8'\n",
    "\n",
    "# 3. Añade la ruta del ejecutable de R (bin/x64 para 64-bit) a la variable PATH.\n",
    "#    Esto permite que Python (y rpy2) encuentren el ejecutable 'R.exe'.\n",
    "r_bin_path = os.path.join(r_home_path, 'bin', 'x64') # Para R de 64 bits (lo más probable)\n",
    "\n",
    "# Añade esta ruta al PATH existente si aún no está.\n",
    "# Es crucial añadirla al inicio del PATH para que se encuentre antes que otras posibles versiones de R o herramientas.\n",
    "if r_bin_path not in os.environ['PATH']:\n",
    "    os.environ['PATH'] = r_bin_path + os.pathsep + os.environ['PATH']\n",
    "\n",
    "# --- AÑADIMOS ESTO PARA DIAGNÓSTICO DE RTOOLS ---\n",
    "# Encuentra la ruta donde RTools debería estar instalado.\n",
    "# Para RTools42, suele ser C:\\rtools42\\usr\\bin o similar.\n",
    "# Puedes verificar la ruta exacta en la instalación de RTools.\n",
    "rtools_path = 'C:\\\\rtools42\\\\usr\\\\bin' # <--- ¡VERIFICA ESTA RUTA DE TU INSTALACIÓN DE RTOOLS!\n",
    "# Si no instalaste en C:\\rtools42, ajusta esta línea.\n",
    "\n",
    "# Añade la ruta de RTools al PATH si no está ya.\n",
    "# Es vital que esta ruta esté en el PATH para que 'sh.exe' y otras herramientas sean encontradas.\n",
    "if rtools_path not in os.environ['PATH']:\n",
    "    os.environ['PATH'] = rtools_path + os.pathsep + os.environ['PATH']\n",
    "\n",
    "print(\"Verificando PATH después de añadir R y RTools:\")\n",
    "print(os.environ['PATH'])\n",
    "\n",
    "# --- TERMINA EL TROUBLESHOOTING / CONFIGURACIÓN ---\n",
    "\n",
    "# Importar las librerías necesarias de Python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "\n",
    "# Configuración de RPy2\n",
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects import pandas2ri, numpy2ri\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.robjects.conversion import localconverter\n",
    "\n",
    "# REMOVE THESE LINES, THEY ARE DEPRECATED\n",
    "# pandas2ri.activate()\n",
    "# numpy2ri.activate()\n",
    "\n",
    "# Importar paquetes R necesarios\n",
    "print(\"\\nImportando paquetes R...\")\n",
    "try:\n",
    "    # Set the conversion context explicitly here using localconverter\n",
    "    # This replaces pandas2ri.activate() and numpy2ri.activate()\n",
    "    with localconverter(ro.default_converter + pandas2ri.converter + numpy2ri.converter) as cv:\n",
    "        base = importr('base')\n",
    "        stats = importr('stats')\n",
    "        utils = importr('utils')\n",
    "        \n",
    "        r_packages = ['ggplot2', 'dplyr', 'lubridate', 'plotly']\n",
    "        for pkg in r_packages:\n",
    "            try:\n",
    "                importr(pkg)\n",
    "                print(f\"  {pkg} cargado correctamente\")\n",
    "            except Exception as pkg_e:\n",
    "                print(f\"  Error al cargar {pkg}: {pkg_e}\")\n",
    "                print(f\"  Intentando instalar {pkg}...\")\n",
    "                utils.install_packages(pkg)\n",
    "                print(f\"  {pkg} instalado y cargado\")\n",
    "                \n",
    "        ggplot2 = importr('ggplot2')\n",
    "        dplyr = importr('dplyr')\n",
    "        lubridate = importr('lubridate')\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"\\n¡ERROR CRÍTICO! RPy2 o R no pudieron inicializarse correctamente: {e}\")\n",
    "    print(\"Por favor, revisa los pasos de instalación de R y RTools, y la configuración de PATH.\")\n",
    "    sys.exit(1) # Salir del script si hay un error fatal con R."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## 1. Generación de Datos Ficticios\n",
    "----\n",
    "Creamos un conjunto de datos simulado de transacciones con tarjeta de crédito para trabajar. Este dataset incluirá información como ID de usuario, fecha y hora, monto, categoría de comercio, ciudad, estado de la transacción y una etiqueta para identificar transacciones fraudulentas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_transacciones_ficticias(n_transacciones=5000):\n",
    "    \"\"\"\n",
    "    Genera un dataset ficticio de transacciones con tarjeta de crédito\n",
    "    \"\"\"\n",
    "    print(f\"Generando {n_transacciones} transacciones ficticias...\")\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    random.seed(42)\n",
    "    \n",
    "    n_usuarios = 500\n",
    "    inicio_fecha = datetime(2024, 1, 1)\n",
    "    fin_fecha = datetime(2024, 12, 31)\n",
    "    \n",
    "    categorias = [\n",
    "        'Supermercado', 'Gasolina', 'Restaurante', 'Ropa', 'Farmacia',\n",
    "        'Electrónicos', 'Online', 'Entretenimiento', 'Salud', 'Educación'\n",
    "    ]\n",
    "    \n",
    "    transacciones = []\n",
    "    \n",
    "    for _ in range(n_transacciones):\n",
    "        usuario_id = f\"USER_{random.randint(1000, 1000 + n_usuarios):04d}\"\n",
    "        \n",
    "        dias_diff = (fin_fecha - inicio_fecha).days\n",
    "        fecha_random = inicio_fecha + timedelta(days=random.randint(0, dias_diff))\n",
    "        \n",
    "        # Hora del día (patrones realistas)\n",
    "        if random.random() < 0.7:  # 70% durante horas normales (6 AM - 10 PM)\n",
    "            hora = random.randint(6, 22)\n",
    "        else:  # 30% durante horas inusuales\n",
    "            # Generar horas entre 23:00 y 05:00\n",
    "            # Opción más robusta: elegir de una lista predefinida de horas inusuales\n",
    "            # o generar en dos rangos separados\n",
    "            hora = random.choice([23, 0, 1, 2, 3, 4, 5]) \n",
    "            # Si quieres asignar pesos diferentes, puedes usar random.choices\n",
    "            # Por ejemplo, para que las horas 0-5 sean más comunes que las 23:00 en este segmento\n",
    "            # hora = random.choices([random.randint(23, 23), random.randint(0, 5)], weights=[1, 6])[0]\n",
    "\n",
    "\n",
    "        fecha_completa = fecha_random.replace(\n",
    "            hour=hora, \n",
    "            minute=random.randint(0, 59),\n",
    "            second=random.randint(0, 59)\n",
    "        )\n",
    "        \n",
    "        categoria = random.choice(categorias)\n",
    "        \n",
    "        montos_base = {\n",
    "            'Supermercado': (20, 150),\n",
    "            'Gasolina': (30, 80),\n",
    "            'Restaurante': (15, 120),\n",
    "            'Ropa': (25, 300),\n",
    "            'Farmacia': (10, 60),\n",
    "            'Electrónicos': (50, 1500),\n",
    "            'Online': (10, 200),\n",
    "            'Entretenimiento': (20, 100),\n",
    "            'Salud': (50, 500),\n",
    "            'Educación': (100, 800)\n",
    "        }\n",
    "        \n",
    "        min_monto, max_monto = montos_base[categoria]\n",
    "        monto = round(np.random.gamma(2, (max_monto - min_monto) / 6) + min_monto, 2)\n",
    "        \n",
    "        ciudades = ['Madrid', 'Barcelona', 'Valencia', 'Sevilla', 'Bilbao', \n",
    "                    'Málaga', 'Zaragoza', 'Murcia', 'Palma', 'Las Palmas']\n",
    "        ciudad = random.choice(ciudades)\n",
    "        \n",
    "        es_fraude = random.random() < 0.02\n",
    "        \n",
    "        if es_fraude:\n",
    "            monto *= random.uniform(3, 10)\n",
    "            if random.random() < 0.5:\n",
    "                # Horas inusuales para fraude\n",
    "                # Asegurarse de que el rango de horas de fraude también sea válido\n",
    "                hora_fraude = random.choice([1, 2, 3, 4]) # Más probable en madrugada profunda\n",
    "                fecha_completa = fecha_completa.replace(hour=hora_fraude)\n",
    "        \n",
    "        if es_fraude and random.random() < 0.3:\n",
    "            estado = 'Rechazada'\n",
    "        else:\n",
    "            estado = random.choices(\n",
    "                ['Aprobada', 'Rechazada', 'Pendiente'],\n",
    "                weights=[0.92, 0.06, 0.02]\n",
    "            )[0]\n",
    "        \n",
    "        transacciones.append({\n",
    "            'usuario_id': usuario_id,\n",
    "            'fecha_hora': fecha_completa,\n",
    "            'monto': monto,\n",
    "            'categoria': categoria,\n",
    "            'ciudad': ciudad,\n",
    "            'estado': estado,\n",
    "            'es_fraude': es_fraude,\n",
    "            'dia_semana': fecha_completa.strftime('%A'),\n",
    "            'hora': fecha_completa.hour,\n",
    "            'mes': fecha_completa.month\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(transacciones)\n",
    "    print(f\"Dataset generado: {len(df)} transacciones\")\n",
    "    print(f\"Transacciones fraudulentas: {df['es_fraude'].sum()} ({df['es_fraude'].mean()*100:.1f}%)\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## 2. Análisis con Python (Pandas)\n",
    "----\n",
    "Realizamos un análisis exploratorio de datos inicial utilizando las capacidades de manipulación de DataFrames de **pandas**. Esto incluye estadísticas descriptivas y agrupaciones por categorías."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analisis_python(df):\n",
    "    \"\"\"\n",
    "    Realiza un análisis básico del dataset de transacciones utilizando la librería pandas de Python.\n",
    "    Incluye estadísticas descriptivas y una detección simple de anomalías.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): El DataFrame de pandas que contiene los datos de transacciones.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: El mismo DataFrame de entrada (no se modifica para el retorno en este caso).\n",
    "    \"\"\"\n",
    "    print(\"\\nANÁLISIS CON PYTHON (pandas)\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # `df['monto'].describe()` genera estadísticas descriptivas básicas para la columna 'monto',\n",
    "    # incluyendo conteo, media, desviación estándar, valores mínimo y máximo, y cuartiles.\n",
    "    print(\"Estadísticas Básicas del Monto:\")\n",
    "    print(df['monto'].describe())\n",
    "    \n",
    "    # `groupby('categoria')` agrupa el DataFrame por la columna 'categoria'.\n",
    "    # `.agg()` aplica múltiples funciones de agregación a las columnas especificadas:\n",
    "    # - 'monto': se cuenta el número de transacciones (`'count'`), se calcula el monto promedio (`'mean'`)\n",
    "    #   y el monto total (`'sum'`) por categoría.\n",
    "    # - 'es_fraude': se suma para obtener el número total de transacciones fraudulentas por categoría\n",
    "    #   (ya que `True` se considera 1 y `False` como 0).\n",
    "    # `.round(2)` redondea los resultados a dos decimales.\n",
    "    print(\"\\nAnálisis por Categoría:\")\n",
    "    categoria_stats = df.groupby('categoria').agg({\n",
    "        'monto': ['count', 'mean', 'sum'],  \n",
    "        'es_fraude': 'sum'                 \n",
    "    }).round(2)\n",
    "    print(categoria_stats)\n",
    "    \n",
    "    # Detección básica de anomalías basada en el monto de la transacción.\n",
    "    # Se calcula el percentil 99 de la columna 'monto'. Esto significa que el 99% de las transacciones\n",
    "    # tienen un monto igual o inferior a este valor.\n",
    "    print(\"\\nDetección Básica de Anomalías:\")\n",
    "    q99 = df['monto'].quantile(0.99)  \n",
    "    # Se filtran las transacciones cuyo monto es estrictamente mayor que el percentil 99.\n",
    "    # Estas transacciones se consideran anomalías o valores atípicos en términos de monto.\n",
    "    anomalias = df[df['monto'] > q99] \n",
    "    print(f\"Transacciones con monto > P99 (EUR{q99:.2f}): {len(anomalias)}\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## 3. Análisis Estadístico Avanzado con R\n",
    "----\n",
    "Aquí explotamos el poder de R para análisis estadísticos más complejos, como tests de normalidad, ANOVA, modelos de regresión logística y análisis de series temporales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analisis_estadistico_r(df):\n",
    "    \"\"\"\n",
    "    Realiza análisis estadísticos avanzados utilizando las capacidades de R a través de RPy2.\n",
    "    Incluye tests de normalidad, ANOVA para comparar grupos, un modelo de regresión logística\n",
    "    para la detección de fraude, y un análisis de series temporales.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): El DataFrame de pandas que contiene los datos de transacciones.\n",
    "    \"\"\"\n",
    "    print(\"\\nANÁLISIS ESTADÍSTICO AVANZADO CON R\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    try:\n",
    "        # Se utiliza `localconverter(pandas2ri.converter)` para asegurar que el DataFrame de pandas\n",
    "        # se convierte correctamente a un DataFrame de R dentro de este bloque.\n",
    "        with localconverter(pandas2ri.converter):\n",
    "            df_r = pandas2ri.py2rpy(df)\n",
    "            # El DataFrame de R se asigna a una variable global en el entorno de R (`transacciones`).\n",
    "            # Esto permite que los scripts de R subsiguientes accedan a los datos fácilmente.\n",
    "            ro.globalenv['transacciones'] = df_r\n",
    "        \n",
    "        # ### 1. Análisis de distribución con tests estadísticos\n",
    "        # Se realizan tests de normalidad para evaluar si la distribución de los montos de las transacciones\n",
    "        # se aproxima a una distribución normal.\n",
    "        print(\"Tests de Normalidad y Distribución...\")\n",
    "        \n",
    "        # Se ejecuta un bloque de código R directamente utilizando `ro.r()`.\n",
    "        # - `sample(transacciones$monto, 1000)`: Toma una muestra aleatoria de 1000 montos. El test de Shapiro-Wilk es más fiable con muestras más pequeñas.\n",
    "        # - `shapiro.test()`: Realiza el test de normalidad de Shapiro-Wilk. Un p-value > 0.05 sugiere que los datos son normalmente distribuidos.\n",
    "        # - `ks.test()`: Realiza el test de Kolmogorov-Smirnov para comparar la distribución de la muestra con una distribución normal teórica.\n",
    "        # Se devuelve una lista de resultados desde R a Python.\n",
    "        resultado_shapiro = ro.r('''\n",
    "            # Test de normalidad Shapiro-Wilk (apropiado para muestras pequeñas a moderadas)\n",
    "            muestra_monto <- sample(transacciones$monto, 1000)\n",
    "            shapiro_test <- shapiro.test(muestra_monto)\n",
    "            \n",
    "            # Test de Kolmogorov-Smirnov para comparar con una distribución normal\n",
    "            # Se compara la distribución de la muestra con una distribución normal teórica\n",
    "            # que tiene la misma media y desviación estándar que la muestra.\n",
    "            ks_test <- ks.test(muestra_monto, \"pnorm\", \n",
    "                               mean = mean(muestra_monto), \n",
    "                               sd = sd(muestra_monto))\n",
    "            \n",
    "            # Se devuelven los p-valores de ambos tests y una bandera booleana\n",
    "            # que indica si la distribución puede considerarse normal basándose en Shapiro-Wilk (p > 0.05).\n",
    "            list(\n",
    "                shapiro_p = shapiro_test$p.value,\n",
    "                ks_p = ks_test$p.value,\n",
    "                distribucion_normal = shapiro_test$p.value > 0.05\n",
    "            )\n",
    "        ''')\n",
    "        \n",
    "        # Se imprimen los p-valores obtenidos y la conclusión sobre la normalidad de la distribución.\n",
    "        print(f\"  Shapiro-Wilk p-value: {resultado_shapiro[0][0]:.6f}\")\n",
    "        print(f\"  Kolmogorov-Smirnov p-value: {resultado_shapiro[1][0]:.6f}\")\n",
    "        print(f\"  ¿Distribución normal?: {'Sí' if resultado_shapiro[2][0] else 'No'}\")\n",
    "        \n",
    "        # ### 2. Análisis de varianza (ANOVA) por categoría\n",
    "        # El ANOVA se utiliza para determinar si existen diferencias estadísticamente significativas\n",
    "        # en las medias de los montos de las transacciones entre las diferentes categorías de comercio.\n",
    "        print(\"\\nAnálisis de Varianza (ANOVA) por Categoría...\")\n",
    "        \n",
    "        anova_resultado = ro.r('''\n",
    "            # `aov(monto ~ categoria, data = transacciones)`: Realiza el análisis de varianza.\n",
    "            # `monto` es la variable dependiente y `categoria` es el factor de agrupación.\n",
    "            anova_resultado <- aov(monto ~ categoria, data = transacciones)\n",
    "            # `summary()`: Proporciona un resumen detallado de los resultados del ANOVA, incluyendo el estadístico F y el p-value.\n",
    "            anova_summary <- summary(anova_resultado)\n",
    "            \n",
    "            # `TukeyHSD()`: Realiza un test post-hoc de Tukey HSD (Honest Significant Difference).\n",
    "            # Este test se usa cuando el ANOVA es significativo para identificar qué pares de categorías específicas\n",
    "            # tienen diferencias de medias significativas, controlando la tasa de error por comparaciones múltiples.\n",
    "            tukey_resultado <- TukeyHSD(anova_resultado)\n",
    "            \n",
    "            # Se devuelven el estadístico F, el p-value y una bandera booleana de significancia.\n",
    "            list(\n",
    "                f_statistic = anova_summary[[1]][1,4], # Estadístico F del ANOVA\n",
    "                p_value = anova_summary[[1]][1,5],     # P-value del ANOVA\n",
    "                significativo = anova_summary[[1]][1,5] < 0.05 # True si el p-value es menor que 0.05\n",
    "            )\n",
    "        ''')\n",
    "        \n",
    "        # Se imprimen los resultados del ANOVA.\n",
    "        print(f\"  F-statistic: {anova_resultado[0][0]:.4f}\")\n",
    "        print(f\"  P-value: {anova_resultado[1][0]:.6f}\")\n",
    "        print(f\"  ¿Diferencias significativas?: {'Sí' if anova_resultado[2][0] else 'No'}\")\n",
    "        \n",
    "        # ### 3. Modelo de regresión logística para detección de fraude\n",
    "        # Se construye un modelo de regresión logística para predecir la probabilidad de que una transacción\n",
    "        # sea fraudulenta (`es_fraude`) basándose en `monto`, `hora` y `categoria`.\n",
    "        print(\"\\nModelo de Regresión Logística para Detección de Fraude...\")\n",
    "        \n",
    "        modelo_fraude = ro.r('''\n",
    "            # Preparación de datos: Se crea una nueva columna `hora_cat` dividiendo la hora en intervalos.\n",
    "            # Esto puede ayudar al modelo a capturar patrones relacionados con franjas horarias específicas.\n",
    "            transacciones$hora_cat <- cut(transacciones$hora, \n",
    "                                          breaks = c(0, 6, 12, 18, 24),\n",
    "                                          labels = c(\"Madrugada\", \"Mañana\", \"Tarde\", \"Noche\"),\n",
    "                                          include.lowest = TRUE)\n",
    "            \n",
    "            # `glm()`: Función para ajustar modelos lineales generalizados.\n",
    "            # `es_fraude ~ monto + hora + categoria`: Fórmula del modelo, donde `es_fraude` es la variable dependiente (binaria).\n",
    "            # `family = binomial()`: Especifica que es un modelo de regresión logística (para respuestas binarias).\n",
    "            modelo <- glm(es_fraude ~ monto + hora + categoria, \n",
    "                          data = transacciones, \n",
    "                          family = binomial())\n",
    "            \n",
    "            # `summary(modelo)`: Proporciona un resumen detallado del modelo, incluyendo coeficientes, errores estándar, etc.\n",
    "            modelo_summary <- summary(modelo)\n",
    "            \n",
    "            # Predicciones: Se obtienen las probabilidades predichas por el modelo (`type = \"response\"`).\n",
    "            predicciones <- predict(modelo, type = \"response\")\n",
    "            # Se convierten las probabilidades en clases binarias (TRUE/FALSE) utilizando un umbral de 0.5.\n",
    "            pred_clase <- ifelse(predicciones > 0.5, TRUE, FALSE)\n",
    "            # `table()`: Crea una matriz de confusión comparando las etiquetas reales con las predichas.\n",
    "            matriz_confusion <- table(transacciones$es_fraude, pred_clase)\n",
    "            \n",
    "            # Cálculo de métricas de evaluación del modelo:\n",
    "            # - Precisión: TP / (TP + FP). Proporción de predicciones positivas correctas.\n",
    "            precision <- matriz_confusion[2,2] / sum(matriz_confusion[,2])\n",
    "            # - Recall (Sensibilidad): TP / (TP + FN). Proporción de casos positivos reales identificados correctamente.\n",
    "            recall <- matriz_confusion[2,2] / sum(matriz_confusion[2,])\n",
    "            # - F1-Score: Media armónica de Precisión y Recall. Útil cuando hay un desequilibrio de clases.\n",
    "            f1_score <- 2 * (precision * recall) / (precision + recall)\n",
    "            \n",
    "            # Se devuelve el AIC (Criterio de Información de Akaike), las métricas de evaluación y los coeficientes del modelo.\n",
    "            list(\n",
    "                aic = modelo$aic,\n",
    "                precision = precision,\n",
    "                recall = recall,\n",
    "                f1_score = f1_score,\n",
    "                coeficientes = modelo$coefficients\n",
    "            )\n",
    "        ''')\n",
    "        \n",
    "        # Se imprimen las métricas de evaluación del modelo de fraude.\n",
    "        print(f\"  AIC del modelo: {modelo_fraude[0][0]:.2f}\")\n",
    "        print(f\"  Precision: {modelo_fraude[1][0]:.4f}\")\n",
    "        print(f\"  Recall: {modelo_fraude[2][0]:.4f}\")\n",
    "        print(f\"  F1-Score: {modelo_fraude[3][0]:.4f}\")\n",
    "        \n",
    "        # ### 4. Análisis de series temporales\n",
    "        # Se analiza el patrón de los montos de las transacciones a lo largo del tiempo para identificar tendencias y estacionalidades.\n",
    "        print(\"\\nAnálisis de Series Temporales...\")\n",
    "        \n",
    "        serie_temporal = ro.r('''\n",
    "            library(lubridate) # Se carga la librería `lubridate` para facilitar la manipulación de fechas.\n",
    "            \n",
    "            # Se convierte la columna `fecha_hora` a un formato de solo fecha (`as.Date`).\n",
    "            transacciones$fecha <- as.Date(transacciones$fecha_hora)\n",
    "            # Se agrupan los datos por `fecha` y se suman los `monto` para obtener el total diario.\n",
    "            serie_diaria <- aggregate(monto ~ fecha, data = transacciones, sum)\n",
    "            \n",
    "            # `ts()`: Crea un objeto de serie temporal en R.\n",
    "            # `serie_diaria$monto`: Los datos numéricos de la serie temporal.\n",
    "            # `frequency = 7`: Indica que la serie tiene una frecuencia semanal (7 observaciones por ciclo).\n",
    "            ts_datos <- ts(serie_diaria$monto, frequency = 7) \n",
    "            \n",
    "            # `decompose()`: Descompone la serie temporal en sus componentes de tendencia, estacionalidad y residuo.\n",
    "            # Esto ayuda a visualizar y entender los patrones a largo plazo y los ciclos repetitivos.\n",
    "            decomp <- decompose(ts_datos)\n",
    "            \n",
    "            # Se calcula la media de la componente de tendencia y la varianza de la componente estacional.\n",
    "            # `na.rm = TRUE` para ignorar los valores `NA` (not available).\n",
    "            tendencia_media <- mean(decomp$trend, na.rm = TRUE)\n",
    "            estacionalidad_var <- var(decomp$seasonal, na.rm = TRUE)\n",
    "            \n",
    "            # Se devuelven las estadísticas calculadas y el número de observaciones en la serie temporal.\n",
    "            list(\n",
    "                tendencia_media = tendencia_media,\n",
    "                varianza_estacional = estacionalidad_var,\n",
    "                observaciones = length(ts_datos)\n",
    "            )\n",
    "        ''')\n",
    "        \n",
    "        # Se imprimen los resultados del análisis de series temporales.\n",
    "        print(f\"  Tendencia media: EUR{serie_temporal[0][0]:.2f}\")\n",
    "        print(f\"  Varianza estacional: {serie_temporal[1][0]:.2f}\")\n",
    "        print(f\"  Observaciones: {int(serie_temporal[2][0])}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        # Manejo de errores específicos para el análisis en R.\n",
    "        print(f\"Error en análisis R: {e}\")\n",
    "        print(\"Verifica que R y los paquetes requeridos estén instalados y funcionando correctamente.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## 4. Visualización Avanzada con GGPlot2\n",
    "----\n",
    "Generamos gráficos de alta calidad utilizando la librería **ggplot2** de R, conocida por su capacidad para crear visualizaciones estéticas y personalizables. Los gráficos se guardarán como archivos PNG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualizacion_r(df):\n",
    "    \"\"\"\n",
    "    Crea visualizaciones avanzadas utilizando la poderosa librería ggplot2 de R.\n",
    "    Los gráficos generados se guardan como archivos PNG en el directorio de trabajo actual.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): El DataFrame de pandas que contiene los datos de transacciones.\n",
    "    \"\"\"\n",
    "    print(\"\\nVISUALIZACIÓN AVANZADA CON GGPLOT2\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    try:\n",
    "        # Se convierte el DataFrame de pandas a un DataFrame de R para que ggplot2 pueda trabajar con él.\n",
    "        with localconverter(pandas2ri.converter):\n",
    "            df_r = pandas2ri.py2rpy(df)\n",
    "            ro.globalenv['datos_viz'] = df_r # Se asigna a una variable global en R para su uso en los scripts R.\n",
    "        \n",
    "        # ### 1. Gráfico de distribución de montos por categoría\n",
    "        # Se crea un boxplot para visualizar la distribución de los montos de transacciones\n",
    "        # para cada categoría de comercio. Se añaden puntos individuales para mostrar la densidad de datos.\n",
    "        print(\"Creando gráfico de distribución por categoría...\")\n",
    "        \n",
    "        ro.r('''\n",
    "            library(ggplot2) # Se carga la librería ggplot2 para gráficos.\n",
    "            library(dplyr)   # Se carga la librería dplyr para manipulación de datos (piping).\n",
    "            \n",
    "            # `ggplot()`: Inicializa el objeto gráfico, especificando el DataFrame (`datos_viz`) y las estéticas (`aes`).\n",
    "            # `x = categoria`: La variable en el eje X será la categoría.\n",
    "            # `y = monto`: La variable en el eje Y será el monto.\n",
    "            # `fill = categoria`: Rellena las cajas y puntos según la categoría.\n",
    "            p1 <- ggplot(datos_viz, aes(x = categoria, y = monto, fill = categoria)) +\n",
    "                geom_boxplot() + # Añade una capa de boxplots para mostrar la distribución.\n",
    "                # `geom_jitter()`: Añade puntos individuales con un poco de \"ruido\" para evitar superposición y mostrar la densidad real.\n",
    "                # `alpha = 0.3`: Transparencia de los puntos.\n",
    "                # `width = 0.2`: Ancho del jitter.\n",
    "                # `size = 0.5`: Tamaño de los puntos.\n",
    "                geom_jitter(alpha = 0.3, width = 0.2, size = 0.5) +\n",
    "                theme_minimal() + # Aplica un tema minimalista al gráfico.\n",
    "                # `theme(axis.text.x = element_text(angle = 45, hjust = 1))`: Rota las etiquetas del eje X para mejor legibilidad.\n",
    "                theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n",
    "                # `labs()`: Define los títulos y etiquetas del gráfico.\n",
    "                labs(title = \"Distribución de Montos por Categoría\",\n",
    "                     subtitle = \"Análisis de Transacciones con Tarjeta de Crédito\",\n",
    "                     x = \"Categoría\", y = \"Monto (EUR)\",\n",
    "                     fill = \"Categoría\") +\n",
    "                scale_fill_viridis_d() # Aplica una paleta de colores discreta de la familia Viridis.\n",
    "            \n",
    "            # `ggsave()`: Guarda el gráfico como un archivo de imagen PNG.\n",
    "            # `width` y `height`: Dimensiones del gráfico en pulgadas.\n",
    "            # `dpi`: Resolución en puntos por pulgada.\n",
    "            ggsave(\"distribucion_categorias.png\", p1, width = 12, height = 8, dpi = 300)\n",
    "            print(\"Gráfico guardado: distribucion_categorias.png\")\n",
    "        ''')\n",
    "        \n",
    "        # ### 2. Análisis temporal de transacciones\n",
    "        # Se crea un gráfico de líneas para mostrar la evolución semanal del número de transacciones,\n",
    "        # diferenciando entre transacciones normales y fraudulentas.\n",
    "        print(\"Creando gráfico de análisis temporal...\")\n",
    "        \n",
    "        ro.r('''\n",
    "            # Preparación de datos para el análisis temporal:\n",
    "            datos_viz$fecha <- as.Date(datos_viz$fecha_hora) # Convierte la columna de fecha y hora a solo fecha.\n",
    "            datos_viz$semana <- format(datos_viz$fecha, \"%Y-%U\") # Extrae el año y el número de semana (ej., \"2024-01\").\n",
    "            \n",
    "            # Se agrupan los datos por semana y por si la transacción es fraudulenta (`es_fraude`).\n",
    "            # Luego se resume el número total de transacciones y el monto total para cada grupo.\n",
    "            datos_semana <- datos_viz %>%\n",
    "                group_by(semana, es_fraude) %>%\n",
    "                summarise(\n",
    "                    total_transacciones = n(),       # `n()` cuenta el número de filas en cada grupo.\n",
    "                    monto_total = sum(monto),  # `sum(monto)` suma los montos en cada grupo.\n",
    "                    .groups = 'drop'           # Elimina los grupos una vez finalizada la sumarización.\n",
    "                )\n",
    "            \n",
    "            # Gráfico de series temporales:\n",
    "            p2 <- ggplot(datos_semana, aes(x = semana, y = total_transacciones, \n",
    "                                           color = factor(es_fraude))) +\n",
    "                geom_line(aes(group = factor(es_fraude)), linewidth = 1.2) + # Crea líneas conectando los puntos, agrupadas por `es_fraude`.\n",
    "                geom_point(size = 2) + # Añade puntos en cada observación.\n",
    "                theme_minimal() +\n",
    "                theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n",
    "                labs(title = \"Evolución Temporal de Transacciones\",\n",
    "                     subtitle = \"Comparación entre Transacciones Normales y Fraudulentas\",\n",
    "                     x = \"Semana\", y = \"Número de Transacciones\",\n",
    "                     color = \"Tipo\") +\n",
    "                # `scale_color_manual()`: Asigna colores específicos a los valores de `es_fraude` (FALSE y TRUE).\n",
    "                scale_color_manual(values = c(\"FALSE\" = \"#2E86AB\", \"TRUE\" = \"#F24236\"),\n",
    "                                   labels = c(\"Normal\", \"Fraude\")) +\n",
    "                # `facet_wrap()`: Divide el gráfico en paneles separados para cada valor de `es_fraude`.\n",
    "                # `scales = \"free_y\"`: Permite que los ejes Y de cada panel tengan escalas independientes, útil si las magnitudes son muy diferentes.\n",
    "                # `labeller`: Personaliza las etiquetas de los paneles.\n",
    "                facet_wrap(~factor(es_fraude), scales = \"free_y\", \n",
    "                           labeller = labeller(.default = c(\"FALSE\" = \"Transacciones Normales\",\n",
    "                                                             \"TRUE\" = \"Transacciones Fraudulentas\")))\n",
    "            \n",
    "            ggsave(\"evolucion_temporal.png\", p2, width = 14, height = 8, dpi = 300)\n",
    "            print(\"Gráfico guardado: evolucion_temporal.png\")\n",
    "        ''')\n",
    "        \n",
    "        # ### 3. Heatmap de patrones por hora y día\n",
    "        # Se crea un mapa de calor para visualizar la intensidad de las transacciones (número o monto)\n",
    "        # en función de la hora del día y el día de la semana.\n",
    "        print(\"Creando heatmap de patrones temporales...\")\n",
    "        \n",
    "        ro.r('''\n",
    "            # Preparación de datos para el heatmap:\n",
    "            # Se convierte `dia_semana` a un factor numérico para asegurar un orden correcto en el eje Y del heatmap.\n",
    "            datos_viz$dia_semana_num <- as.numeric(factor(datos_viz$dia_semana, \n",
    "                levels = c(\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \n",
    "                          \"Friday\", \"Saturday\", \"Sunday\")))\n",
    "            \n",
    "            # Se agrupan los datos por hora y día de la semana para calcular métricas agregadas.\n",
    "            heatmap_data <- datos_viz %>%\n",
    "                group_by(hora, dia_semana, dia_semana_num) %>%\n",
    "                summarise(\n",
    "                    num_transacciones = n(),       # Número de transacciones por cada celda (hora, día).\n",
    "                    monto_promedio = mean(monto),  # Monto promedio por celda.\n",
    "                    tasa_fraude = mean(as.numeric(es_fraude)), # Tasa de fraude por celda.\n",
    "                    .groups = 'drop'\n",
    "                )\n",
    "            \n",
    "            # Heatmap de actividad:\n",
    "            p3 <- ggplot(heatmap_data, aes(x = hora, y = reorder(dia_semana, dia_semana_num), \n",
    "                                           fill = num_transacciones)) +\n",
    "                geom_tile() + # `geom_tile()` crea las \"baldosas\" del heatmap, donde el color se mapea a `fill`.\n",
    "                # `scale_fill_gradient()`: Define la escala de color para el relleno, de blanco (bajo) a azul oscuro (alto).\n",
    "                scale_fill_gradient(low = \"white\", high = \"darkblue\", name = \"Transacciones\") +\n",
    "                theme_minimal() +\n",
    "                labs(title = \"Patrón de Actividad: Transacciones por Hora y Día\",\n",
    "                     subtitle = \"Heatmap de Intensidad de Transacciones\",\n",
    "                     x = \"Hora del Día\", y = \"Día de la Semana\") +\n",
    "                # `scale_x_continuous()`: Ajusta las marcas del eje X para que aparezcan cada 2 horas (0, 2, 4, ..., 23).\n",
    "                scale_x_continuous(breaks = seq(0, 23, 2))\n",
    "            \n",
    "            ggsave(\"heatmap_actividad.png\", p3, width = 12, height = 6, dpi = 300)\n",
    "            print(\"Gráfico guardado: heatmap_actividad.png\")\n",
    "        ''')\n",
    "        \n",
    "        print(\"\\nTodas las visualizaciones han sido generadas exitosamente!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        # Manejo de errores específicos para la visualización en R.\n",
    "        print(f\"Error en visualización: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## 5. Comparación Python vs R (Rendimiento)\n",
    "----\n",
    "Realizamos una comparación de rendimiento entre operaciones estadísticas básicas ejecutadas en **Python (NumPy)** y en **R (a través de RPy2)**. Esto ayuda a entender el \"overhead\" de la interoperabilidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparacion_performance():\n",
    "    \"\"\"\n",
    "    Compara el rendimiento de operaciones estadísticas básicas (media, desviación estándar, cuantiles)\n",
    "    entre Python (NumPy) y R (a través de RPy2) utilizando un conjunto de datos grande.\n",
    "    \"\"\"\n",
    "    print(\"\\nCOMPARACIÓN DE PERFORMANCE PYTHON vs R\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Generar un conjunto de datos de prueba grande (100,000 puntos) con una distribución gamma.\n",
    "    n_test = 100000\n",
    "    datos_test = np.random.gamma(2, 1000, n_test)\n",
    "    \n",
    "    # --- Test de rendimiento en Python (NumPy) ---\n",
    "    start_time = time.time() # Registra el tiempo de inicio antes de las operaciones en Python.\n",
    "    media_py = np.mean(datos_test)      # Calcula la media del array.\n",
    "    std_py = np.std(datos_test)         # Calcula la desviación estándar del array.\n",
    "    # Calcula los percentiles 25, 50, 75, 95 y 99.\n",
    "    quantiles_py = np.percentile(datos_test, [25, 50, 75, 95, 99])\n",
    "    tiempo_python = time.time() - start_time # Calcula el tiempo transcurrido para las operaciones en Python.\n",
    "    \n",
    "    # --- Test de rendimiento en R (a través de RPy2) ---\n",
    "    start_time = time.time() # Registra el tiempo de inicio antes de las operaciones en R.\n",
    "    # Convierte el array de NumPy `datos_test` a un vector de tipo flotante de R (`ro.FloatVector`)\n",
    "    # y lo asigna a una variable global en el entorno de R (`datos_test`).\n",
    "    ro.globalenv['datos_test'] = ro.FloatVector(datos_test)\n",
    "    \n",
    "    # Ejecuta un bloque de código R para calcular las mismas estadísticas.\n",
    "    resultado_r = ro.r('''\n",
    "        media_r <- mean(datos_test) # Calcula la media en R.\n",
    "        std_r <- sd(datos_test)     # Calcula la desviación estándar en R.\n",
    "        # Calcula los cuantiles en R.\n",
    "        quantiles_r <- quantile(datos_test, c(0.25, 0.5, 0.75, 0.95, 0.99))\n",
    "        \n",
    "        # Devuelve los resultados en una lista de R, que RPy2 convertirá de nuevo a un objeto Python.\n",
    "        list(media = media_r, std = std_r, quantiles = quantiles_r)\n",
    "    ''')\n",
    "    tiempo_r = time.time() - start_time # Calcula el tiempo transcurrido para las operaciones en R.\n",
    "    \n",
    "    # Imprime los tiempos y los resultados de ambos entornos para la comparación.\n",
    "    print(f\"Python - Tiempo: {tiempo_python:.4f}s\")\n",
    "    print(f\"    Media: {media_py:.2f}, Std: {std_py:.2f}\")\n",
    "    \n",
    "    print(f\"R - Tiempo: {tiempo_r:.4f}s\")\n",
    "    # Los resultados de R se acceden como elementos de la lista `resultado_r`.\n",
    "    print(f\"    Media: {resultado_r[0][0]:.2f}, Std: {resultado_r[1][0]:.2f}\")\n",
    "    \n",
    "    # Calcula y muestra el ratio de velocidad.\n",
    "    # Es importante señalar que el tiempo de R incluye el `overhead` de la comunicación con RPy2\n",
    "    # y las conversiones de datos, lo que puede hacer que R parezca más lento para operaciones simples.\n",
    "    print(f\"\\nRatio de velocidad (R / Python): {tiempo_r/tiempo_python:.2f}x\")\n",
    "    print(\"Nota: R incluye overhead de RPy2 y conversión de datos, lo que puede afectar la comparación directa.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Función Principal\n",
    "----\n",
    "Esta función coordina la ejecución de todos los pasos del análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Función principal que orquesta la ejecución de todo el análisis de transacciones,\n",
    "    demostrando la integración de Python y R a través de RPy2.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"ANÁLISIS DE TRANSACCIONES CON TARJETA DE CRÉDITO\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Demostrando el poder de RPy2 para integrar Python y R\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # 1. Generar datos ficticios de transacciones.\n",
    "    df = generar_transacciones_ficticias(5000)\n",
    "    \n",
    "    # --- Impresión de las primeras 10 filas del DataFrame ---\n",
    "    print(\"\\n--- Primeras 10 filas del DataFrame generado ---\")\n",
    "    print(df.head(10))\n",
    "    print(\"--------------------------------------------------\")\n",
    "    # ---------------------------------------------------\n",
    "    \n",
    "    # 2. Realizar un análisis exploratorio básico utilizando pandas en Python.\n",
    "    df = analisis_python(df)\n",
    "    \n",
    "    # 3. Ejecutar análisis estadístico avanzado utilizando el entorno de R.\n",
    "    analisis_estadistico_r(df)\n",
    "    \n",
    "    # 4. Crear visualizaciones profesionales con ggplot2 en R.\n",
    "    visualizacion_r(df)\n",
    "    \n",
    "    # 5. Comparar el rendimiento de operaciones entre Python y R.\n",
    "    comparacion_performance()\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"RESUMEN DE VENTAJAS DE RPy2 DEMOSTRADAS:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"- Manipulación de datos eficiente con pandas (Python)\")\n",
    "    print(\"- Tests estadísticos avanzados con R\")\n",
    "    print(\"- Visualizaciones profesionales con ggplot2\")\n",
    "    print(\"- Modelos estadísticos especializados (GLM)\")\n",
    "    print(\"- Análisis de series temporales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANÁLISIS DE TRANSACCIONES CON TARJETA DE CRÉDITO\n",
      "============================================================\n",
      "Demostrando el poder de RPy2 para integrar Python y R\n",
      "============================================================\n",
      "Generando 5000 transacciones ficticias...\n",
      "Dataset generado: 5000 transacciones\n",
      "Transacciones fraudulentas: 97 (1.9%)\n",
      "\n",
      "--- Primeras 10 filas del DataFrame generado ---\n",
      "  usuario_id          fecha_hora   monto     categoria      ciudad    estado  \\\n",
      "0  USER_1327 2024-02-27 14:15:14   56.89   Restaurante   Barcelona  Aprobada   \n",
      "1  USER_1044 2024-10-29 06:05:13   93.50          Ropa       Palma  Aprobada   \n",
      "2  USER_1366 2024-11-28 02:14:28  261.27     Educación      Bilbao  Aprobada   \n",
      "3  USER_1412 2024-03-22 16:17:09   88.36          Ropa      Málaga  Aprobada   \n",
      "4  USER_1183 2024-06-25 07:46:29  398.73         Salud   Barcelona  Aprobada   \n",
      "5  USER_1282 2024-05-30 03:56:55  742.79  Electrónicos  Las Palmas  Aprobada   \n",
      "6  USER_1338 2024-04-26 23:54:14   39.43      Gasolina    Zaragoza  Aprobada   \n",
      "7  USER_1186 2024-03-24 12:42:17   50.58      Gasolina  Las Palmas  Aprobada   \n",
      "8  USER_1125 2024-03-24 14:59:40  199.92         Salud     Sevilla  Aprobada   \n",
      "9  USER_1397 2024-01-29 07:51:20   16.84        Online      Bilbao  Aprobada   \n",
      "\n",
      "   es_fraude dia_semana  hora  mes  \n",
      "0      False     martes    14    2  \n",
      "1      False     martes     6   10  \n",
      "2      False     jueves     2   11  \n",
      "3      False    viernes    16    3  \n",
      "4      False     martes     7    6  \n",
      "5      False     jueves     3    5  \n",
      "6      False    viernes    23    4  \n",
      "7      False    domingo    12    3  \n",
      "8      False    domingo    14    3  \n",
      "9      False      lunes     7    1  \n",
      "--------------------------------------------------\n",
      "\n",
      "ANÁLISIS CON PYTHON (pandas)\n",
      "==================================================\n",
      "Estadísticas Básicas del Monto:\n",
      "count    5000.000000\n",
      "mean      171.033349\n",
      "std       286.600942\n",
      "min        10.500000\n",
      "25%        40.320000\n",
      "50%        69.980000\n",
      "75%       200.072300\n",
      "max      6428.422278\n",
      "Name: monto, dtype: float64\n",
      "\n",
      "Análisis por Categoría:\n",
      "                monto                    es_fraude\n",
      "                count    mean        sum       sum\n",
      "categoria                                         \n",
      "Educación         525  357.79  187838.90         7\n",
      "Electrónicos      543  583.81  317006.46        10\n",
      "Entretenimiento   498   51.04   25416.13        11\n",
      "Farmacia          464   29.34   13614.84         7\n",
      "Gasolina          486   51.48   25021.53         7\n",
      "Online            502   86.74   43545.67        15\n",
      "Restaurante       518   55.65   28826.77        11\n",
      "Ropa              469  132.39   62092.22         6\n",
      "Salud             501  233.25  116858.21        13\n",
      "Supermercado      494   70.74   34946.01        10\n",
      "\n",
      "Detección Básica de Anomalías:\n",
      "Transacciones con monto > P99 (EUR1185.64): 50\n",
      "\n",
      "ANÁLISIS ESTADÍSTICO AVANZADO CON R\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R callback write-console: In addition:   \n",
      "R callback write-console: Warning message:\n",
      "  \n",
      "R callback write-console: In ks.test.default(muestra_monto, \"pnorm\", mean = mean(muestra_monto),  :  \n",
      "R callback write-console: \n",
      "   \n",
      "R callback write-console:  ties should not be present for the Kolmogorov-Smirnov test\n",
      "  \n",
      "R callback write-console: In addition:   \n",
      "R callback write-console: Warning message:\n",
      "  \n",
      "R callback write-console: glm.fit: fitted probabilities numerically 0 or 1 occurred \n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests de Normalidad y Distribución...\n",
      "  Shapiro-Wilk p-value: 0.000000\n",
      "  Kolmogorov-Smirnov p-value: 0.000000\n",
      "  ¿Distribución normal?: No\n",
      "\n",
      "Análisis de Varianza (ANOVA) por Categoría...\n",
      "  F-statistic: 326.9964\n",
      "  P-value: 0.000000\n",
      "  ¿Diferencias significativas?: Sí\n",
      "\n",
      "Modelo de Regresión Logística para Detección de Fraude...\n",
      "  AIC del modelo: 364.16\n",
      "  Precision: 0.8889\n",
      "  Recall: 0.6598\n",
      "  F1-Score: 0.7574\n",
      "\n",
      "Análisis de Series Temporales...\n",
      "  Tendencia media: EUR2331.30\n",
      "  Varianza estacional: 20967.22\n",
      "  Observaciones: 367\n",
      "\n",
      "VISUALIZACIÓN AVANZADA CON GGPLOT2\n",
      "==================================================\n",
      "Creando gráfico de distribución por categoría...\n",
      "[1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R callback write-console: <class 'UnicodeDecodeError'> 'utf-8' codec can't decode byte 0xe1 in position 4: invalid continuation byte <traceback object at 0x000001A0ADB8CA80>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creando gráfico de análisis temporal...\n",
      "[1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R callback write-console: <class 'UnicodeDecodeError'> 'utf-8' codec can't decode byte 0xe1 in position 4: invalid continuation byte <traceback object at 0x000001A0ACA24140>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creando heatmap de patrones temporales...\n",
      "[1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R callback write-console: <class 'UnicodeDecodeError'> 'utf-8' codec can't decode byte 0xe1 in position 4: invalid continuation byte <traceback object at 0x000001A0ACA25340>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Todas las visualizaciones han sido generadas exitosamente!\n",
      "\n",
      "COMPARACIÓN DE PERFORMANCE PYTHON vs R\n",
      "==================================================\n",
      "Python - Tiempo: 0.0030s\n",
      "    Media: 2002.63, Std: 1417.99\n",
      "R - Tiempo: 0.0050s\n",
      "    Media: 2002.63, Std: 1418.00\n",
      "\n",
      "Ratio de velocidad (R / Python): 1.67x\n",
      "Nota: R incluye overhead de RPy2 y conversión de datos, lo que puede afectar la comparación directa.\n",
      "\n",
      "============================================================\n",
      "RESUMEN DE VENTAJAS DE RPy2 DEMOSTRADAS:\n",
      "============================================================\n",
      "- Manipulación de datos eficiente con pandas (Python)\n",
      "- Tests estadísticos avanzados con R\n",
      "- Visualizaciones profesionales con ggplot2\n",
      "- Modelos estadísticos especializados (GLM)\n",
      "- Análisis de series temporales\n"
     ]
    }
   ],
   "source": [
    "# Este bloque asegura que la función `main()` se ejecute solo cuando el script se inicia directamente,\n",
    "# y no cuando se importa como un módulo en otro script.\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de Métricas del Modelo\n",
    "\n",
    "## 1. AIC del modelo: 364.16\n",
    "**¿Qué es?**  \n",
    "El AIC (Criterio de Información de Akaike) es como un \"puntuaje de calidad\" para tu modelo. Intenta estimar qué tan bien el modelo predice nuevos datos, penalizando la complejidad (más variables o reglas).\n",
    "\n",
    "**Interpretación:**  \n",
    "Un AIC más bajo generalmente indica un mejor modelo. No hay un \"buen\" o \"mal\" valor de AIC por sí solo; es más útil para comparar diferentes modelos que intentan resolver el mismo problema. En este caso, el valor 364.16 es una referencia interna de su rendimiento.\n",
    "\n",
    "## 2. Precision: 0.8889\n",
    "**¿Qué es?**  \n",
    "La Precisión nos dice, de todas las transacciones que tu modelo marcó como fraudulentas, ¿cuántas fueron realmente fraudulentas?\n",
    "\n",
    "**Interpretación:**  \n",
    "Un valor de 0.8889 (o 88.89%) es muy bueno. Significa que, si tu modelo dice que una transacción es fraude, hay casi un 89% de posibilidades de que realmente lo sea. Esto es importante para evitar \"falsas alarmas\" que podrían molestar a los clientes.\n",
    "\n",
    "## 3. Recall: 0.6598\n",
    "**¿Qué es?**  \n",
    "El Recall (también conocido como Sensibilidad) nos dice, de todas las transacciones que realmente fueron fraudulentas, ¿cuántas fue capaz de detectar tu modelo?\n",
    "\n",
    "**Interpretación:**  \n",
    "Un valor de 0.6598 (o 65.98%) significa que tu modelo logró identificar alrededor del 66% de todos los fraudes que ocurrieron. Esto es una métrica clave para no dejar pasar fraudes importantes.\n",
    "\n",
    "## 4. F1-Score: 0.7574\n",
    "**¿Qué es?**  \n",
    "El F1-Score es una medida que combina la Precisión y el Recall en un solo número. Es útil cuando las dos métricas son importantes y no quieres sacrificar una por la otra. Es un promedio \"balanceado\".\n",
    "\n",
    "**Interpretación:**  \n",
    "Un F1-Score de 0.7574 (o 75.74%) sugiere un buen equilibrio entre la Precisión y el Recall. El modelo no es perfecto, pero hace un trabajo decente tanto identificando fraudes de forma correcta como detectando una buena parte de ellos.\n",
    "\n",
    "## Resumen General del Rendimiento del Modelo\n",
    "Tu modelo de detección de fraude simulado está mostrando un rendimiento prometedor:\n",
    "\n",
    "- Es bastante preciso cuando identifica un fraude, lo que minimiza las interrupciones a los clientes por falsas alarmas.\n",
    "- Es razonablemente bueno para detectar los fraudes existentes, aunque todavía hay un porcentaje de fraudes reales que podría no capturar (aproximadamente un 34%).\n",
    "- El F1-Score confirma que hay un buen equilibrio general en su capacidad de detección.\n",
    "\n",
    "**Nota importante:**  \n",
    "Para un sistema de detección de fraude real, las empresas a menudo deben decidir si priorizan la precisión (no molestar a los clientes) o el recall (no dejar pasar ningún fraude), dependiendo del costo y la tolerancia al riesgo de cada tipo de error."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
